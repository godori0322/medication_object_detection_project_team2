{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32fe0c31-97b2-4d38-b78e-dcdbcef3d03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ 프로젝트 루트: C:\\Users\\USER\\Documents\\GitHub\\medication_object_detection_project_team2\\Project\n",
      "Python executable: C:\\Users\\USER\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meditation-detection-project-ihVzpsAT-py3.11\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.argv = ['']  # argparse 충돌 방지용\n",
    "# 프로젝트 루트 경로를 조정하세요\n",
    "proj_root = os.path.abspath(os.path.join('..'))\n",
    "if proj_root not in sys.path:\n",
    "    sys.path.insert(0, proj_root)\n",
    "print(\"▶️ 프로젝트 루트:\", proj_root)\n",
    "print(\"Python executable:\", sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "077407e3-27e6-4587-bc84-aa8d4be01a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Device       : cuda\n",
      "▶ cfg          : Namespace(device='cuda', num_epochs=100, num_classes=44199, batch_size=16, lr=0.001, lrf=0.01, lr_scheduler='StepLR', optimizer='SGD', num_workers=0, weight_decay=0.0005, confidence_threshold=0.5, momentum=0.9, tune=False, iterations=300, tune_epochs=30, hyp_path=None, base_dir=WindowsPath('C:/Users/USER/Documents/GitHub/medication_object_detection_project_team2'), data_dir=WindowsPath('C:/Users/USER/Documents/GitHub/medication_object_detection_project_team2/data/ai03-level1-project'), train_image_dir=WindowsPath('C:/Users/USER/Documents/GitHub/medication_object_detection_project_team2/data/ai03-level1-project/train_images'), test_image_dir=WindowsPath('C:/Users/USER/Documents/GitHub/medication_object_detection_project_team2/data/ai03-level1-project/test_images'), annotation_dir=WindowsPath('C:/Users/USER/Documents/GitHub/medication_object_detection_project_team2/data/ai03-level1-project/train_annotations'), output_dir=WindowsPath('C:/Users/USER/Documents/GitHub/medication_object_detection_project_team2/Project/outputs'), checkpoint_dir=WindowsPath('C:/Users/USER/Documents/GitHub/medication_object_detection_project_team2/Project/outputs/checkpoints'), model_checkpoint=WindowsPath('C:/Users/USER/Documents/GitHub/medication_object_detection_project_team2/Project/outputs/checkpoints/pill_detector_best.pth'), log_dir=WindowsPath('C:/Users/USER/Documents/GitHub/medication_object_detection_project_team2/Project/outputs/logs'))\n"
     ]
    }
   ],
   "source": [
    "from src.config import get_config, get_device\n",
    "device = get_device()\n",
    "print(f\"▶ Device       : {device}\")\n",
    "cfg    = get_config()\n",
    "print(f\"▶ cfg          : {cfg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c42f9130-a832-49dc-97b5-d7481ed62428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모든 클래스가 학습/검증 세트에 최소 1개씩 포함되어 있습니다.\n",
      "▶ Train images: 504, rows: 1900\n",
      "▶  Val images: 125, rows: 471\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) 원본 어노테이션 로드\n",
    "df = pd.read_csv('excluded_annotations.csv')\n",
    "\n",
    "# 2) 이미지 리스트와 클래스→이미지 매핑 생성\n",
    "all_images = df['images_file_name'].unique().tolist()\n",
    "class_to_images = {\n",
    "    cls: set(group['images_file_name'])\n",
    "    for cls, group in df.groupby('categories_id')\n",
    "}\n",
    "\n",
    "# 3) 각 클래스별로 1장씩 검증세트에 할당\n",
    "random.seed(42)\n",
    "val_images = set()\n",
    "for cls, imgs in class_to_images.items():\n",
    "    val_images.add(random.choice(list(imgs)))\n",
    "\n",
    "# 4) 원하는 검증 비율(예: 20%) 고려하여 추가 이미지 선택\n",
    "val_ratio     = 0.2\n",
    "n_total       = len(all_images)\n",
    "n_desired_val = int(n_total * val_ratio)\n",
    "remaining     = list(set(all_images) - val_images)\n",
    "n_additional  = max(0, n_desired_val - len(val_images))\n",
    "if n_additional > 0:\n",
    "    val_images.update(random.sample(remaining, n_additional))\n",
    "\n",
    "# 5) 최종 train/val 이미지 집합\n",
    "train_images = set(all_images) - val_images\n",
    "\n",
    "# 6) DataFrame 필터링 (순서를 검증 코드 앞에)\n",
    "train_df = df[df['images_file_name'].isin(train_images)]\n",
    "val_df   = df[df['images_file_name'].isin(val_images)]\n",
    "\n",
    "# 7) train_df, val_df 검증\n",
    "all_classes = df['categories_id'].unique()\n",
    "bad = []\n",
    "for cls in all_classes:\n",
    "    if (train_df['categories_id'] == cls).sum() == 0:\n",
    "        bad.append(f\"{cls}번 클래스가 학습 세트에 없음\")\n",
    "    if (val_df['categories_id'] == cls).sum() == 0:\n",
    "        bad.append(f\"{cls}번 클래스가 검증 세트에 없음\")\n",
    "\n",
    "if not bad:\n",
    "    print(\"✅ 모든 클래스가 학습/검증 세트에 최소 1개씩 포함되어 있습니다.\")\n",
    "else:\n",
    "    print(\"❌ 문제가 있는 클래스:\\n\" + \"\\n\".join(bad))\n",
    "\n",
    "# 8) CSV 저장\n",
    "train_df.to_csv('train_annotations.csv', index=False)\n",
    "val_df.to_csv('val_annotations.csv',   index=False)\n",
    "\n",
    "print(f\"▶ Train images: {len(train_images)}, rows: {len(train_df)}\")\n",
    "print(f\"▶  Val images: {len(val_images)}, rows: {len(val_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa4ba27-c6d4-4407-b3cd-c11e1f9224b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 완료: images/train|val(원본 PNG 복사), labels/train|val(.txt), data.yaml\n"
     ]
    }
   ],
   "source": [
    "# ─────────── 1) 라이브러리 임포트 ───────────\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from PIL import Image  # 사이즈 읽기용\n",
    "\n",
    "# ─────────── 2) 경로 설정 ───────────\n",
    "img_dir      = Path(cfg.train_image_dir)   # 원본 PNG들이 있는 폴더\n",
    "train_csv    = 'train_annotations.csv'\n",
    "val_csv      = 'val_annotations.csv'\n",
    "mapping_csv  = 'category_id_name_mapping.csv'\n",
    "\n",
    "# ─────────── 3) CSV 로드 및 매핑 준비 ───────────\n",
    "train_df   = pd.read_csv(train_csv)\n",
    "val_df     = pd.read_csv(val_csv)\n",
    "mapping_df = pd.read_csv(mapping_csv)\n",
    "orig_ids   = mapping_df['categories_id'].tolist()\n",
    "names      = mapping_df['categories_name'].tolist()\n",
    "id2idx     = {orig_id: idx for idx, orig_id in enumerate(orig_ids)}\n",
    "\n",
    "# ─────────── 4) 이미지 리스트 생성 ───────────\n",
    "train_imgs = train_df['images_file_name'].unique().tolist()\n",
    "val_imgs   = val_df['images_file_name'].unique().tolist()\n",
    "\n",
    "# ─────────── 5) 디렉터리 생성 ───────────\n",
    "(Path('images/train')).mkdir(parents=True, exist_ok=True)\n",
    "(Path('images/val')).mkdir(parents=True, exist_ok=True)\n",
    "(Path('labels/train')).mkdir(parents=True, exist_ok=True)\n",
    "(Path('labels/val')).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def copy_image_and_write_label(df_split, img_list, split):\n",
    "    out_img_dir = Path('images') / split\n",
    "    out_lbl_dir = Path('labels') / split\n",
    "\n",
    "    for img_name in img_list:\n",
    "        src_path = img_dir / img_name\n",
    "        dst_path = out_img_dir / img_name  # 확장자 그대로 유지(모두 PNG라 가정)\n",
    "\n",
    "        # 5-1) 원본 PNG 복사(타임스탬프/메타 보존)\n",
    "        dst_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "\n",
    "        # 5-2) 라벨 작성 (원본 해상도 기준 정규화)\n",
    "        recs = df_split[df_split['images_file_name'] == img_name]\n",
    "        w, h = Image.open(src_path).size\n",
    "        lbl_path = out_lbl_dir / f\"{Path(img_name).stem}.txt\"\n",
    "        with open(lbl_path, 'w', encoding='utf-8') as f:\n",
    "            for _, row in recs.iterrows():\n",
    "                cls = id2idx[int(row['categories_id'])]\n",
    "                x, y, bw, bh = row[['annotations_bbox_x', 'annotations_bbox_y',\n",
    "                                    'annotations_bbox_w', 'annotations_bbox_h']].values.astype(float)\n",
    "                xc = (x + bw/2) / w\n",
    "                yc = (y + bh/2) / h\n",
    "                nw = bw / w\n",
    "                nh = bh / h\n",
    "                f.write(f\"{cls} {xc:.6f} {yc:.6f} {nw:.6f} {nh:.6f}\\n\")\n",
    "\n",
    "# ─────────── 6) 복사 + 라벨 생성 ───────────\n",
    "copy_image_and_write_label(train_df, train_imgs, 'train')\n",
    "copy_image_and_write_label(val_df,   val_imgs,   'val')\n",
    "\n",
    "# ─────────── 7) train.txt & val.txt 생성 (복사된 경로로) ───────────\n",
    "with open('train.txt', 'w', encoding='utf-8') as f:\n",
    "    for nm in train_imgs:\n",
    "        f.write(f\"images/train/{nm}\\n\")\n",
    "\n",
    "with open('val.txt', 'w', encoding='utf-8') as f:\n",
    "    for nm in val_imgs:\n",
    "        f.write(f\"images/val/{nm}\\n\")\n",
    "\n",
    "# ─────────── 8) data.yaml 작성 ───────────\n",
    "data = {\n",
    "    'path': '.',\n",
    "    'train': 'train.txt',\n",
    "    'val':   'val.txt',\n",
    "    'nc':    len(names),\n",
    "    'names': names\n",
    "}\n",
    "with open('data.yaml', 'w', encoding='utf-8') as f:\n",
    "    yaml.dump(data, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "print(\"✅ 완료: images/train|val(원본 PNG 복사), labels/train|val(.txt), data.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f483d898-9918-4752-8880-f830acb6ea40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MedPills (poetry)",
   "language": "python",
   "name": "medpills-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
