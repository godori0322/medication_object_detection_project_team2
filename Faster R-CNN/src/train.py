# src/train.py

import torch
from torch.utils.data import DataLoader, Subset
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import matplotlib.pyplot as plt

# src í´ë”ì˜ ë‹¤ë¥¸ ëª¨ë“ˆê³¼ ì„¤ì • íŒŒì¼ ì„í¬íŠ¸
from . import config
from .dataset import PillDataset
from .model import get_detection_model

# DataLoaderëŠ” ë°°ì¹˜ ë‚´ ì´ë¯¸ì§€ í¬ê¸°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ collate_fnì´ í•„ìš”í•©ë‹ˆë‹¤.
def collate_fn(batch):
    return tuple(zip(*batch))

def main():
    device = torch.device(config.DEVICE)
    
    # 1. ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ
    print("Loading data...")
    full_dataset = PillDataset(
        image_dir=config.TRAIN_IMAGE_DIR,
        annotation_dir=config.TRAIN_ANNOTATION_DIR
    )

    # 2. ë°ì´í„°ë¥¼ í•™ìŠµìš©ê³¼ ê²€ì¦ìš©ìœ¼ë¡œ ë¶„í•  (90% í•™ìŠµ, 10% ê²€ì¦)
    # ë°ì´í„°ì…‹ì˜ ì¸ë±ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    indices = list(range(len(full_dataset)))
    train_indices, val_indices = train_test_split(indices, test_size=0.1, random_state=42, shuffle=True)
    
    # ë¶„í• ëœ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•´ Subset ìƒì„±
    train_dataset = Subset(full_dataset, train_indices)
    val_dataset = Subset(full_dataset, val_indices)
    
    print(f"Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}")

    # 3. ë°ì´í„°ë¡œë” ìƒì„±
    train_loader = DataLoader(
        train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=4
    )
    val_loader = DataLoader(
        val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=4
    )

    # 4. ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
    model = get_detection_model(num_classes=config.NUM_CLASSES).to(device)
    params = [p for p in model.parameters() if p.requires_grad]
    optimizer = torch.optim.SGD(
        params, lr=config.LEARNING_RATE, momentum=0.9, weight_decay=config.WEIGHT_DECAY
    )
    
    print("ğŸš€ Training started!")
    
    # ê° ì—í¬í¬ì˜ ì†ì‹¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    train_losses = []
    val_losses = []
    best_val_loss = float('inf') # ê°€ì¥ ë‚®ì€ ê²€ì¦ ì†ì‹¤ì„ ê¸°ë¡í•˜ê¸° ìœ„í•œ ë³€ìˆ˜

    # 5. í•™ìŠµ ë° ê²€ì¦ ë£¨í”„
    for epoch in range(config.NUM_EPOCHS):
        # --- í•™ìŠµ ë‹¨ê³„ ---
        model.train()
        train_loop = tqdm(train_loader, leave=True)
        total_train_loss = 0
        
        for images, targets in train_loop:
            images = [img.to(device) for img in images]
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

            loss_dict = model(images, targets)
            losses = sum(loss for loss in loss_dict.values())
            
            optimizer.zero_grad()
            losses.backward()
            optimizer.step()

            total_train_loss += losses.item()
            train_loop.set_description(f"Epoch [{epoch+1}/{config.NUM_EPOCHS}]")
            train_loop.set_postfix(train_loss=losses.item())
        
        avg_train_loss = total_train_loss / len(train_loader)
        train_losses.append(avg_train_loss)
        
        # --- ê²€ì¦ ë‹¨ê³„ ---
        model.eval()
        total_val_loss = 0
        with torch.no_grad():
            for images, targets in val_loader:
                images = [img.to(device) for img in images]
                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
                
                loss_dict = model(images, targets)
                losses = sum(loss for loss in loss_dict.values())
                total_val_loss += losses.item()
        
        avg_val_loss = total_val_loss / len(val_loader)
        val_losses.append(avg_val_loss)
        print(f"Epoch {epoch+1} Summary: Avg Train Loss: {avg_train_loss:.4f}, Avg Val Loss: {avg_val_loss:.4f}")

        # 6. ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì˜ ëª¨ë¸ ì €ì¥ (Best Checkpoint)
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(model.state_dict(), config.MODEL_CHECKPOINT)
            print(f"âœ¨ Best model saved at epoch {epoch+1} with validation loss: {best_val_loss:.4f}")

    # 7. í•™ìŠµ ì™„ë£Œ í›„ ì†ì‹¤ ê·¸ë˜í”„ ìƒì„± ë° ì €ì¥
    plt.figure(figsize=(10, 6))
    plt.plot(range(1, config.NUM_EPOCHS + 1), train_losses, marker='o', linestyle='-', label='Training Loss')
    plt.plot(range(1, config.NUM_EPOCHS + 1), val_losses, marker='o', linestyle='--', label='Validation Loss')
    plt.title("Training & Validation Loss Curve")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.grid(True)
    plt.legend()
    plt.xticks(range(1, config.NUM_EPOCHS + 1))
    
    loss_curve_path = config.OUTPUT_DIR / "training_loss_curve.png"
    plt.savefig(loss_curve_path)
    print(f"ğŸ“ˆ Loss curve saved to {loss_curve_path}")


if __name__ == '__main__':
    main()